mlquantify
==========

.. py:module:: mlquantify


Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/mlquantify/base/index
   /autoapi/mlquantify/classification/index
   /autoapi/mlquantify/evaluation/index
   /autoapi/mlquantify/methods/index
   /autoapi/mlquantify/model_selection/index
   /autoapi/mlquantify/plots/index
   /autoapi/mlquantify/utils/index


Attributes
----------

.. autoapisummary::

   mlquantify.MEASURES
   mlquantify.AGGREGATIVE
   mlquantify.NON_AGGREGATIVE
   mlquantify.META
   mlquantify.METHODS


Classes
-------

.. autoapisummary::

   mlquantify.PWKCLF
   mlquantify.APP
   mlquantify.NPP
   mlquantify.CC
   mlquantify.PCC
   mlquantify.GAC
   mlquantify.GPAC
   mlquantify.FM
   mlquantify.EMQ
   mlquantify.PWK
   mlquantify.ACC
   mlquantify.MAX
   mlquantify.X_method
   mlquantify.T50
   mlquantify.MS
   mlquantify.MS2
   mlquantify.PACC
   mlquantify.HDy
   mlquantify.DyS
   mlquantify.SORD
   mlquantify.SMM
   mlquantify.DySsyn
   mlquantify.HDx
   mlquantify.Ensemble
   mlquantify.GridSearchQ


Functions
---------

.. autoapisummary::

   mlquantify.absolute_error
   mlquantify.kullback_leibler_divergence
   mlquantify.normalized_kullback_leibler_divergence
   mlquantify.relative_absolute_error
   mlquantify.normalized_absolute_error
   mlquantify.bias
   mlquantify.normalized_relative_absolute_error
   mlquantify.squared_error
   mlquantify.mean_squared_error
   mlquantify.get_measure
   mlquantify.get_method
   mlquantify.normalize_prevalence
   mlquantify.parallel
   mlquantify.get_real_prev
   mlquantify.make_prevs
   mlquantify.generate_artificial_indexes
   mlquantify.round_protocol_df
   mlquantify.convert_columns_to_arrays
   mlquantify.load_quantifier
   mlquantify.getHist
   mlquantify.sqEuclidean
   mlquantify.probsymm
   mlquantify.hellinger
   mlquantify.topsoe
   mlquantify.ternary_search
   mlquantify.compute_table
   mlquantify.compute_tpr
   mlquantify.compute_fpr
   mlquantify.adjust_threshold
   mlquantify.get_scores
   mlquantify.MoSS
   mlquantify.protocol_boxplot
   mlquantify.protocol_lineplot
   mlquantify.class_distribution_plot


Package Contents
----------------

.. py:class:: PWKCLF(alpha=1, n_neighbors=10, algorithm='auto', metric='euclidean', leaf_size=30, p=2, metric_params=None, n_jobs=None)

   Bases: :py:obj:`sklearn.base.BaseEstimator`


   Learner based on k-Nearest Neighborst (KNN) to use on the method PWK, 
   that also is based on KNN.


   .. py:attribute:: alpha


   .. py:attribute:: n_neighbors


   .. py:attribute:: nbrs


   .. py:attribute:: Y
      :value: None



   .. py:attribute:: Y_map
      :value: None



   .. py:attribute:: w
      :value: None



   .. py:attribute:: y
      :value: None



   .. py:method:: fit(X, y)


   .. py:method:: predict(X)


.. py:function:: absolute_error(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: kullback_leibler_divergence(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: normalized_kullback_leibler_divergence(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: relative_absolute_error(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: normalized_absolute_error(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: bias(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: normalized_relative_absolute_error(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: squared_error(prev_real: numpy.any, prev_pred: numpy.any)

.. py:function:: mean_squared_error(prev_real: numpy.any, prev_pred: numpy.any)

.. py:data:: MEASURES

.. py:function:: get_measure(measure: str)

.. py:class:: APP(models: Union[List[Union[str, mlquantify.base.Quantifier]], str, mlquantify.base.Quantifier], batch_size: Union[List[int], int], learner: sklearn.base.BaseEstimator = None, n_prevs: int = 100, n_iterations: int = 1, n_jobs: int = 1, random_state: int = 32, verbose: bool = False, return_type: str = 'predictions', measures: List[str] = None)

   Bases: :py:obj:`mlquantify.evaluation.protocol._Protocol.Protocol`


   Artificial Prevalence Protocol. It splits a test into several
   samples varying prevalence and sample size, with n iterations.
   For a list of Quantifiers, it computes training and testing 
   for each one and returns either a table of results with error measures
   or just the predictions.


   .. py:attribute:: n_prevs


   .. py:method:: predict_protocol(X_test, y_test) -> tuple

      Generates several samples with artificial prevalences and sizes.
      For each model, predicts with this sample, aggregating all together
      with a pandas dataframe if requested, or else just the predictions.

      Args:
          X_test (array-like): Features of the test set.
          y_test (array-like): Labels of the test set.

      Returns:
          tuple: predictions containing the model name, real prev, pred prev, and batch size



   .. py:method:: _new_sample(X, y, prev: List[float], batch_size: int) -> tuple

      Generates a new sample with a specified prevalence and size.

      Args:
          X (array-like): Features from which to take the new sample.
          y (array-like): Labels from which to take the new sample.
          prev (List[float]): The specified prevalences.
          batch_size (int): Sample size.

      Returns:
          tuple: New sample's features and labels.



   .. py:method:: _delayed_predict(args) -> tuple

      Method predicts into the new sample, is delayed for running 
      in parallel for eficciency purposes

      Args:
          args (Any): arguments to use 

      Returns:
          tuple: returns the (method name, real_prev, pred_prev and sample_size)



   .. py:method:: _generate_artificial_prevalences(n_dim: int, n_prev: int, n_iter: int) -> numpy.ndarray

      Generates n artificial prevalences with n dimensions.

      Args:
          n_dim (int): Number of dimensions for the artificial prevalence.
          n_prev (int): Number of prevalence points to generate.
          n_iter (int): Number of iterations.

      Returns:
          np.ndarray: Generated artificial prevalences.



   .. py:method:: _generate_args(X_test, y_test, prevs)

      Generates arguments for parallel processing based on the model, prevalence, and batch size.

      Args:
          X_test (array-like): Features of the test set.
          y_test (array-like): Labels of the test set.
          prevs (np.ndarray): Artificial prevalences generated.

      Returns:
          List[tuple]: List of arguments for parallel processing.



.. py:class:: NPP(models: Union[List[Union[str, mlquantify.base.Quantifier]], str, mlquantify.base.Quantifier], batch_size: Union[List[int], int], learner: sklearn.base.BaseEstimator = None, n_iterations: int = 1, n_jobs: int = 1, random_state: int = 32, verbose: bool = False, return_type: str = 'predictions', measures: List[str] = None)

   Bases: :py:obj:`mlquantify.evaluation.protocol._Protocol.Protocol`


   Base class for implementing different quantification protocols.

   This abstract class provides a structure for creating protocols that involve
   fitting quantification models to training data and generating predictions on test data.
   It supports parallel processing, multiple iterations, and different output formats.

   Args:
       models (Union[List[Union[str, Quantifier]], str, Quantifier]): 
           List of quantification models, a single model name, or 'all' for all models.
       batch_size (Union[List[int], int]): 
           Size of the batches to be processed, or a list of sizes.
       learner (BaseEstimator, optional): 
           Machine learning model to be used with the quantifiers. Required for model methods.
       n_iterations (int, optional): 
           Number of iterations for the protocol. Default is 1.
       n_jobs (int, optional): 
           Number of jobs to run in parallel. Default is 1.
       random_state (int, optional): 
           Seed for random number generation. Default is 32.
       verbose (bool, optional): 
           Whether to print progress messages. Default is False.
       return_type (str, optional): 
           Type of return value ('predictions' or 'table'). Default is 'predictions'.
       measures (List[str], optional): 
           List of error measures to calculate. Must be in MEASURES or None. Default is None.


   .. py:method:: predict_protocol(X_test, y_test) -> tuple
      :abstractmethod:


      Abstract method that every protocol has to implement 



   .. py:method:: _new_sample(X, y, prev: List[float], batch_size: int) -> tuple
      :abstractmethod:


      Abstract method of sample extraction for each protocol

      Returns:
          tuple: tuple containing the X_sample and the y_sample



   .. py:method:: _delayed_predict(args) -> tuple
      :abstractmethod:


      abstract method for predicting in the extracted
      samples, is delayed for running in parallel for 
      eficciency purposes.



.. py:data:: AGGREGATIVE

.. py:data:: NON_AGGREGATIVE

.. py:data:: META

.. py:data:: METHODS

.. py:function:: get_method(method: str)

.. py:class:: CC(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   Classify and Count. The simplest quantification method
   involves classifying each instance and then counting the 
   number of instances assigned to each class to estimate 
   the class prevalence.


   .. py:attribute:: learner


   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



.. py:class:: PCC(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   Probabilistic Classify and Count. This method
   takes the probabilistic predictions and takes the 
   mean of them for each class.


   .. py:attribute:: learner


   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



.. py:class:: GAC(learner: sklearn.base.BaseEstimator, train_size: float = 0.6, random_state: int = None)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   Generalized Adjusted Count. It applies a 
   classifier to build a system of linear equations, 
   and solve it via constrained least-squares regression.


   .. py:attribute:: learner


   .. py:attribute:: cond_prob_matrix
      :value: None



   .. py:attribute:: train_size


   .. py:attribute:: random_state


   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



   .. py:method:: get_cond_prob_matrix(classes: list, y_labels: numpy.ndarray, predictions: numpy.ndarray) -> numpy.ndarray
      :classmethod:


      Estimate the conditional probability matrix P(yi|yj)



   .. py:method:: solve_adjustment(cond_prob_matrix, predicted_prevalences)
      :classmethod:


      Solve the linear system Ax = B with A=cond_prob_matrix and B=predicted_prevalences
              



.. py:class:: GPAC(learner: sklearn.base.BaseEstimator, train_size: float = 0.6, random_state: int = None)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   Generalized Probabilistic Adjusted Count. Like 
   GAC, it also build a system of linear equations, but 
   utilize the confidence scores from probabilistic 
   classifiers as in the PAC method.


   .. py:attribute:: learner


   .. py:attribute:: cond_prob_matrix
      :value: None



   .. py:attribute:: train_size


   .. py:attribute:: random_state


   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



   .. py:method:: get_cond_prob_matrix(classes: list, y_labels: numpy.ndarray, y_pred: numpy.ndarray) -> numpy.ndarray
      :classmethod:


      Estimate the matrix where entry (i,j) is the estimate of P(yi|yj)



.. py:class:: FM(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   The Friedman Method. Similar to GPAC, 
   but instead of averaging the confidence scores
   from probabilistic classifiers, it uses the proportion
   of confidence scores that are higher or lower than the
   expected class frequencies found in the training data.


   .. py:attribute:: learner


   .. py:attribute:: CM
      :value: None



   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



.. py:class:: EMQ(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   Expectation Maximisation Quantifier. It is a method that
   ajust the priors and posteriors probabilities of a learner


   .. py:attribute:: MAX_ITER
      :value: 1000



   .. py:attribute:: EPSILON
      :value: 1e-06



   .. py:attribute:: learner


   .. py:attribute:: priors
      :value: None



   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



   .. py:method:: predict_proba(X, epsilon: float = EPSILON, max_iter: int = MAX_ITER) -> numpy.ndarray


   .. py:method:: EM(priors, posteriors, epsilon=EPSILON, max_iter=MAX_ITER)
      :classmethod:


      Expectaion Maximization function, it iterates several times
      and At each iteration step, both the a posteriori and the a 
      priori probabilities are reestimated sequentially for each new 
      observation and each class. The iterative procedure proceeds 
      until the convergence of the estimated probabilities.

      Args:
          priors (array-like): priors probabilites of the train.
          posteriors (array-like): posteriors probabiblities of the test.
          epsilon (float): value that helps to indify the convergence.
          max_iter (int): max number of iterations.

      Returns:
          the predicted prevalence and the ajusted posteriors.



.. py:class:: PWK(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.base.AggregativeQuantifier`


   Nearest-Neighbor based Quantification. This method 
   is based on nearest-neighbor based classification to the
   setting of quantification. In this k-NN approach, it applies
   a weighting scheme which applies less weight on neighbors 
   from the majority class.
   Must be used with PWKCLF to work as expected.


   .. py:attribute:: learner


   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



.. py:class:: ACC(learner: sklearn.base.BaseEstimator, threshold: float = 0.5)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Adjusted Classify and Count or Adjusted Count. Is a 
   base method for the threhold methods.
       As described on the Threshold base class, this method 
   estimate the true positive and false positive rates from
   the training data and utilize them to adjust the output 
   of the CC method.


   .. py:attribute:: threshold


   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: MAX(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Threshold MAX. This method tries to use the
   threshold where it maximizes the difference between
   tpr and fpr to use in the denominator of the equation.


   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: X_method(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Threshold X. This method tries to
   use the threshold where fpr = 1 - tpr


   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: T50(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Threshold 50. This method tries to
   use the threshold where tpr = 0.5.


   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: MS(learner: sklearn.base.BaseEstimator, threshold: float = 0.5)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Median Sweep. This method uses an
   ensemble of such threshold-based methods and 
   takes the median prediction.


   .. py:attribute:: threshold


   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: MS2(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Median Sweep 2. It relies on the same
   strategy of the Median Sweep, but compute 
   the median only for cases in which 
   tpr -fpr > 0.25


   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: PACC(learner: sklearn.base.BaseEstimator, threshold: float = 0.5)

   Bases: :py:obj:`mlquantify.methods.aggregative.ThreholdOptm._ThreholdOptimization.ThresholdOptimization`


   Probabilistic Adjusted Classify and Count. 
   This method adapts the AC approach by using average
   classconditional confidences from a probabilistic 
   classifier instead of true positive and false positive rates.


   .. py:attribute:: threshold


   .. py:method:: _predict_method(X)

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



   .. py:method:: best_tprfpr(thresholds: numpy.ndarray, tprs: numpy.ndarray, fprs: numpy.ndarray) -> tuple

      Abstract method for determining the best TPR and FPR to use in the equation



.. py:class:: HDy(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.mixtureModels._MixtureModel.MixtureModel`


   Hellinger Distance Minimization. The method
   is based on computing the hellinger distance of 
   two distributions, test distribution and the mixture
   of the positive and negative distribution of the train.


   .. py:method:: _compute_prevalence(test_scores: numpy.ndarray) -> float

      Abstract method for computing the prevalence using the test scores 



   .. py:method:: best_distance(X_test) -> float


   .. py:method:: GetMinDistancesHDy(test_scores: numpy.ndarray) -> tuple


.. py:class:: DyS(learner: sklearn.base.BaseEstimator, measure: str = 'topsoe', bins_size: numpy.ndarray = None)

   Bases: :py:obj:`mlquantify.methods.aggregative.mixtureModels._MixtureModel.MixtureModel`


   Distribution y-Similarity framework. Is a 
   method that generalises the HDy approach by 
   considering the dissimilarity function DS as 
   a parameter of the model


   .. py:attribute:: bins_size


   .. py:attribute:: measure


   .. py:attribute:: prevs
      :value: None



   .. py:method:: _compute_prevalence(test_scores: numpy.ndarray) -> float

      Abstract method for computing the prevalence using the test scores 



   .. py:method:: best_distance(X_test) -> float


   .. py:method:: GetMinDistancesDyS(test_scores) -> list


.. py:class:: SORD(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.mixtureModels._MixtureModel.MixtureModel`


   Sample Ordinal Distance. Is a method 
   that does not rely on distributions, but 
   estimates the prevalence of the positive 
   class in a test dataset by calculating and 
   minimizing a sample ordinal distance measure 
   between the test scores and known positive 
   and negative scores.


   .. py:attribute:: best_distance_index
      :value: None



   .. py:method:: _compute_prevalence(test_scores: numpy.ndarray) -> float

      Abstract method for computing the prevalence using the test scores 



   .. py:method:: _calculate_distances(test_scores: numpy.ndarray)


.. py:class:: SMM(learner: sklearn.base.BaseEstimator)

   Bases: :py:obj:`mlquantify.methods.aggregative.mixtureModels._MixtureModel.MixtureModel`


   Sample Mean Matching. The method is 
   a member of the DyS framework that uses 
   simple means to represent the score 
   distribution for positive, negative 
   and unlabelled scores.


   .. py:method:: _compute_prevalence(test_scores: numpy.ndarray) -> float

      Abstract method for computing the prevalence using the test scores 



.. py:class:: DySsyn(learner: sklearn.base.BaseEstimator, measure: str = 'topsoe', merge_factor: numpy.ndarray = None, bins_size: numpy.ndarray = None, alpha_train: float = 0.5, n: int = None)

   Bases: :py:obj:`mlquantify.methods.aggregative.mixtureModels._MixtureModel.MixtureModel`


   Synthetic Distribution y-Similarity. This method works the
   same as DyS method, but istead of using the train scores, it 
   generates them via MoSS (Model for Score Simulation) which 
   generate a spectrum of score distributions from highly separated
   scores to fully mixed scores.


   .. py:attribute:: bins_size


   .. py:attribute:: merge_factor


   .. py:attribute:: alpha_train


   .. py:attribute:: n


   .. py:attribute:: measure


   .. py:attribute:: m
      :value: None



   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _compute_prevalence(test_scores: numpy.ndarray) -> float

      Abstract method for computing the prevalence using the test scores 



   .. py:method:: best_distance(X_test)


   .. py:method:: GetMinDistancesDySsyn(test_scores) -> list


.. py:class:: HDx(bins_size: numpy.ndarray = None)

   Bases: :py:obj:`mlquantify.base.NonAggregativeQuantifier`


   Hellinger Distance Minimization. The method is similar 
   to the HDy method, but istead of computing the hellinger 
   distance of the scores (generated via classifier), HDx 
   computes the distance of each one of the features of the 
   dataset


   .. py:attribute:: bins_size


   .. py:attribute:: neg_features
      :value: None



   .. py:attribute:: pos_features
      :value: None



   .. py:method:: _fit_method(X, y)

      Abstract fit method that each quantification method must implement.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.
          learner_fitted (bool): Whether the learner is already fitted.
          cv_folds (int): Number of cross-validation folds.



   .. py:method:: _predict_method(X) -> dict

      Abstract predict method that each quantification method must implement.

      Args:
          X (array-like): Test data to generate class prevalences.

      Returns:
          dict: Dictionary with class:prevalence for each class.



.. py:class:: Ensemble(quantifier: mlquantify.base.Quantifier, size: int = 50, min_prop: float = 0.1, selection_metric: str = 'all', p_metric: float = 0.25, return_type: str = 'mean', max_sample_size: int = None, max_trials: int = 100, n_jobs: int = 1, verbose: bool = False)

   Bases: :py:obj:`mlquantify.base.Quantifier`


   Abstract Class for quantifiers.


   .. py:attribute:: SELECTION_METRICS

      Ensemble method, based on the articles:
      Pérez-Gállego, P., Quevedo, J. R., & del Coz, J. J. (2017).
      Using ensembles for problems with characterizable changes in data distribution: A case study on quantification.
      Information Fusion, 34, 87-100.
      and
      Pérez-Gállego, P., Castano, A., Quevedo, J. R., & del Coz, J. J. (2019). 
      Dynamic ensemble selection for quantification tasks. 
      Information Fusion, 45, 1-15.

          This approach of Ensemble is made of taking multiple
      samples varying class proportions on each, and for the 
      predictions, it takes the k models which as the minimum
      seletion metric, which are:
       - all -> return all the predictions
       - ptr -> computes the selected error measure
       - ds -> computes the hellinger distance of the train and test
       distributions for each model




   .. py:attribute:: base_quantifier


   .. py:attribute:: size


   .. py:attribute:: min_prop


   .. py:attribute:: p_metric


   .. py:attribute:: selection_metric


   .. py:attribute:: return_type


   .. py:attribute:: n_jobs


   .. py:attribute:: proba_generator
      :value: None



   .. py:attribute:: verbose


   .. py:attribute:: max_sample_size


   .. py:attribute:: max_trials


   .. py:method:: sout(msg)


   .. py:method:: fit(X, y)


   .. py:method:: predict(X)


   .. py:method:: ptr_selection_metric(prevalences)

      Selects the prevalences made by models that have been trained on samples with a prevalence that is most similar
      to a first approximation of the test prevalence as made by all models in the ensemble.



   .. py:method:: ds_get_posteriors(X, y)

      In the original article, this procedure is not described in a sufficient level of detail. The paper only says
      that the distribution of posterior probabilities from training and test examples is compared by means of the
      Hellinger Distance. However, how these posterior probabilities are generated is not specified. In the article,
      a Logistic Regressor (LR) is used as the classifier device and that could be used for this purpose. However, in
      general, a Quantifier is not necessarily an instance of Aggreggative Probabilistic Quantifiers, and so, that the
      quantifier builds on top of a probabilistic classifier cannot be given for granted. Additionally, it would not
      be correct to generate the posterior probabilities for training documents that have concurred in training the
      classifier that generates them.
      This function thus generates the posterior probabilities for all training documents in a cross-validation way,
      using a LR with hyperparameters that have previously been optimized via grid search in 5FCV.
      :return P,f, where P is a ndarray containing the posterior probabilities of the training data, generated via
      cross-validation and using an optimized LR, and the function to be used in order to generate posterior
      probabilities for test X.



   .. py:method:: ds_selection_metric(prevalences, test)


.. py:function:: normalize_prevalence(prevalences: numpy.ndarray, classes: list)

.. py:function:: parallel(func, elements, n_jobs: int = 1, *args)

.. py:function:: get_real_prev(y) -> dict

.. py:function:: make_prevs(ndim: int) -> list

   Generate a list of n_dim values uniformly distributed between 0 and 1 that sum exactly to 1.

   Args:
   n_dim (int): Number of values in the list.

   Returns:
   list: List of n_dim values that sum to 1.


.. py:function:: generate_artificial_indexes(y, prevalence: list, sample_size: int, classes: list)

.. py:function:: round_protocol_df(dataframe: pandas.DataFrame, frac: int = 3)

.. py:function:: convert_columns_to_arrays(df, columns: list = ['PRED_PREVS', 'REAL_PREVS'])

   Converts the specified columns from string of arrays to numpy arrays

   Args:
       df (array-like): the dataframe from which to change convert the coluns
       columns (list, optional): the coluns with string of arrays, default is the options for
       the protocol dataframes


.. py:function:: load_quantifier(path: str)

.. py:function:: getHist(scores, nbins)

.. py:function:: sqEuclidean(dist1, dist2)

.. py:function:: probsymm(dist1, dist2)

.. py:function:: hellinger(dist1, dist2)

.. py:function:: topsoe(dist1, dist2)

.. py:function:: ternary_search(left, right, f, eps=0.0001)

   This function applies Ternary search


.. py:function:: compute_table(y, y_pred, classes)

.. py:function:: compute_tpr(TP, FN)

.. py:function:: compute_fpr(FP, TN)

.. py:function:: adjust_threshold(y, probabilities: numpy.ndarray, classes: numpy.ndarray) -> tuple

.. py:function:: get_scores(X, y, learner, folds: int = 10, learner_fitted: bool = False) -> tuple

.. py:function:: MoSS(n: int, alpha: float, m: float)

.. py:function:: protocol_boxplot(table_protocol: pandas.DataFrame, x: str, y: str, methods: Optional[List[str]] = None, title: Optional[str] = None, legend: bool = True, save_path: Optional[str] = None, order: Optional[str] = None, plot_params: Optional[Dict[str, Any]] = None)

   Plots a boxplot based on the provided DataFrame and selected methods.


.. py:function:: protocol_lineplot(table_protocol: pandas.DataFrame, methods: Union[List[str], str, None], x: str, y: str, title: Optional[str] = None, legend: bool = True, save_path: Optional[str] = None, group_by: str = 'mean', pos_alpha: int = 1, plot_params: Optional[Dict[str, Any]] = None)

   Plots a line plot based on the provided DataFrame of the protocol and selected methods.


.. py:function:: class_distribution_plot(values: Union[List, numpy.ndarray], labels: Union[List, numpy.ndarray], bins: int = 30, title: Optional[str] = None, legend: bool = True, save_path: Optional[str] = None, plot_params: Optional[Dict[str, Any]] = None)

   Plot overlaid histograms of class distributions.

   This function creates a plot with overlaid histograms, each representing the distribution
   of a different class or category. Custom colors, titles, legends, and other plot parameters 
   can be applied to enhance visualization.

   Args:
       values (Union[List, np.ndarray]): 
           A list of arrays or a single array containing values for specific classes or categories.
       labels (Union[List, np.ndarray]): 
           A list or an array of labels corresponding to each value set in `values`. 
           Must be the same length as `values`.
       bins (int, optional): 
           Number of bins to use in the histograms. Default is 30.
       title (Optional[str], optional): 
           Title of the plot. If not provided, no title will be displayed.
       legend (bool, optional): 
           Whether to display a legend. Default is True.
       save_path (Optional[str], optional): 
           File path to save the plot image. If not provided, the plot will not be saved.
       plot_params (Optional[Dict[str, Any]], optional): 
           Dictionary of custom plotting parameters to apply. Default is None.

   Raises:
       AssertionError: 
           If the number of labels does not match the number of value sets.



.. py:class:: GridSearchQ(model: mlquantify.base.Quantifier, param_grid: dict, protocol: str = 'app', n_prevs: int = None, n_repetitions: int = 1, scoring: Union[List[str], str] = 'ae', refit: bool = True, val_split: float = 0.4, n_jobs: int = 1, random_seed: int = 42, timeout: int = -1, verbose: bool = False)

   Bases: :py:obj:`mlquantify.base.Quantifier`


   Hyperparameter optimization for quantification models using grid search.

   Args:
       model (Quantifier): The base quantification model.
       param_grid (dict): Hyperparameters to search over.
       protocol (str, optional): Quantification protocol ('app' or 'npp'). Defaults to 'app'.
       n_prevs (int, optional): Number of prevalence points for APP. Defaults to None.
       n_repetitions (int, optional): Number of repetitions for NPP. Defaults to 1.
       scoring (Union[List[str], str], optional): Metric(s) for evaluation. Defaults to "mae".
       refit (bool, optional): Refit model on best parameters. Defaults to True.
       val_split (float, optional): Proportion of data for validation. Defaults to 0.4.
       n_jobs (int, optional): Number of parallel jobs. Defaults to 1.
       random_seed (int, optional): Seed for reproducibility. Defaults to 42.
       timeout (int, optional): Max time per parameter combination (seconds). Defaults to -1.
       verbose (bool, optional): Verbosity of output. Defaults to False.


   .. py:attribute:: model


   .. py:attribute:: param_grid


   .. py:attribute:: protocol


   .. py:attribute:: n_prevs


   .. py:attribute:: n_repetitions


   .. py:attribute:: refit


   .. py:attribute:: val_split


   .. py:attribute:: n_jobs


   .. py:attribute:: random_seed


   .. py:attribute:: timeout


   .. py:attribute:: verbose


   .. py:attribute:: scoring


   .. py:method:: sout(msg)

      Prints messages if verbose is True.



   .. py:method:: __get_protocol(model, sample_size)

      Get the appropriate protocol instance.

      Args:
          model (Quantifier): The quantification model.
          sample_size (int): The sample size for batch processing.

      Returns:
          object: Instance of APP or NPP protocol.



   .. py:method:: fit(X, y)

      Fit the quantifier model and perform grid search.

      Args:
          X (array-like): Training features.
          y (array-like): Training labels.

      Returns:
          self: Fitted GridSearchQ instance.



   .. py:method:: predict(X)

      Make predictions using the best found model.

      Args:
          X (array-like): Data to predict on.

      Returns:
          array-like: Predictions.



   .. py:property:: classes_

      Get the classes of the best model.

      Returns:
          array-like: The classes.



   .. py:method:: set_params(**parameters)

      Set the hyperparameters for grid search.

      Args:
          parameters (dict): Hyperparameters to set.



   .. py:method:: get_params(deep=True)

      Get the parameters of the best model.

      Args:
          deep (bool, optional): If True, will return the parameters for this estimator and contained subobjects. Defaults to True.

      Returns:
          dict: Parameters of the best model.



   .. py:method:: best_model()

      Return the best model after fitting.

      Returns:
          Quantifier: The best model.

      Raises:
          ValueError: If called before fitting.



   .. py:method:: _timeout_handler(signum, frame)

      Handle timeouts during evaluation.

      Args:
          signum (int): Signal number.
          frame (object): Current stack frame.

      Raises:
          TimeoutError: When the timeout is reached.



