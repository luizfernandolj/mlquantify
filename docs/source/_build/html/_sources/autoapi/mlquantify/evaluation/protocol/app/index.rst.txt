mlquantify.evaluation.protocol.app
==================================

.. py:module:: mlquantify.evaluation.protocol.app


Classes
-------

.. autoapisummary::

   mlquantify.evaluation.protocol.app.APP


Module Contents
---------------

.. py:class:: APP(models: Union[List[Union[str, mlquantify.base.Quantifier]], str, mlquantify.base.Quantifier], batch_size: Union[List[int], int], learner: sklearn.base.BaseEstimator = None, n_prevs: int = 100, n_iterations: int = 1, n_jobs: int = 1, random_state: int = 32, verbose: bool = False, return_type: str = 'predictions', measures: List[str] = None)

   Bases: :py:obj:`mlquantify.evaluation.protocol._Protocol.Protocol`


   Artificial Prevalence Protocol. It splits a test into several
   samples varying prevalence and sample size, with n iterations.
   For a list of Quantifiers, it computes training and testing 
   for each one and returns either a table of results with error measures
   or just the predictions.


   .. py:attribute:: n_prevs


   .. py:method:: predict_protocol(X_test, y_test) -> tuple

      Generates several samples with artificial prevalences and sizes.
      For each model, predicts with this sample, aggregating all together
      with a pandas dataframe if requested, or else just the predictions.

      Args:
          X_test (array-like): Features of the test set.
          y_test (array-like): Labels of the test set.

      Returns:
          tuple: predictions containing the model name, real prev, pred prev, and batch size



   .. py:method:: _new_sample(X, y, prev: List[float], batch_size: int) -> tuple

      Generates a new sample with a specified prevalence and size.

      Args:
          X (array-like): Features from which to take the new sample.
          y (array-like): Labels from which to take the new sample.
          prev (List[float]): The specified prevalences.
          batch_size (int): Sample size.

      Returns:
          tuple: New sample's features and labels.



   .. py:method:: _delayed_predict(args) -> tuple

      Method predicts into the new sample, is delayed for running 
      in parallel for eficciency purposes

      Args:
          args (Any): arguments to use 

      Returns:
          tuple: returns the (method name, real_prev, pred_prev and sample_size)



   .. py:method:: _generate_artificial_prevalences(n_dim: int, n_prev: int, n_iter: int) -> numpy.ndarray

      Generates n artificial prevalences with n dimensions.

      Args:
          n_dim (int): Number of dimensions for the artificial prevalence.
          n_prev (int): Number of prevalence points to generate.
          n_iter (int): Number of iterations.

      Returns:
          np.ndarray: Generated artificial prevalences.



   .. py:method:: _generate_args(X_test, y_test, prevs)

      Generates arguments for parallel processing based on the model, prevalence, and batch size.

      Args:
          X_test (array-like): Features of the test set.
          y_test (array-like): Labels of the test set.
          prevs (np.ndarray): Artificial prevalences generated.

      Returns:
          List[tuple]: List of arguments for parallel processing.



