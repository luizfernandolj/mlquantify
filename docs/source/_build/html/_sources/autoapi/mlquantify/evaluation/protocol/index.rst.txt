mlquantify.evaluation.protocol
==============================

.. py:module:: mlquantify.evaluation.protocol


Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/mlquantify/evaluation/protocol/_Protocol/index
   /autoapi/mlquantify/evaluation/protocol/app/index
   /autoapi/mlquantify/evaluation/protocol/npp/index


Classes
-------

.. autoapisummary::

   mlquantify.evaluation.protocol.APP
   mlquantify.evaluation.protocol.NPP


Package Contents
----------------

.. py:class:: APP(models: Union[List[Union[str, mlquantify.base.Quantifier]], str, mlquantify.base.Quantifier], batch_size: Union[List[int], int], learner: sklearn.base.BaseEstimator = None, n_prevs: int = 100, n_iterations: int = 1, n_jobs: int = 1, random_state: int = 32, verbose: bool = False, return_type: str = 'predictions', measures: List[str] = None)

   Bases: :py:obj:`mlquantify.evaluation.protocol._Protocol.Protocol`


   Artificial Prevalence Protocol. It splits a test into several
   samples varying prevalence and sample size, with n iterations.
   For a list of Quantifiers, it computes training and testing 
   for each one and returns either a table of results with error measures
   or just the predictions.


   .. py:attribute:: n_prevs


   .. py:method:: predict_protocol(X_test, y_test) -> tuple

      Generates several samples with artificial prevalences and sizes.
      For each model, predicts with this sample, aggregating all together
      with a pandas dataframe if requested, or else just the predictions.

      Args:
          X_test (array-like): Features of the test set.
          y_test (array-like): Labels of the test set.

      Returns:
          tuple: predictions containing the model name, real prev, pred prev, and batch size



   .. py:method:: _new_sample(X, y, prev: List[float], batch_size: int) -> tuple

      Generates a new sample with a specified prevalence and size.

      Args:
          X (array-like): Features from which to take the new sample.
          y (array-like): Labels from which to take the new sample.
          prev (List[float]): The specified prevalences.
          batch_size (int): Sample size.

      Returns:
          tuple: New sample's features and labels.



   .. py:method:: _delayed_predict(args) -> tuple

      Method predicts into the new sample, is delayed for running 
      in parallel for eficciency purposes

      Args:
          args (Any): arguments to use 

      Returns:
          tuple: returns the (method name, real_prev, pred_prev and sample_size)



   .. py:method:: _generate_artificial_prevalences(n_dim: int, n_prev: int, n_iter: int) -> numpy.ndarray

      Generates n artificial prevalences with n dimensions.

      Args:
          n_dim (int): Number of dimensions for the artificial prevalence.
          n_prev (int): Number of prevalence points to generate.
          n_iter (int): Number of iterations.

      Returns:
          np.ndarray: Generated artificial prevalences.



   .. py:method:: _generate_args(X_test, y_test, prevs)

      Generates arguments for parallel processing based on the model, prevalence, and batch size.

      Args:
          X_test (array-like): Features of the test set.
          y_test (array-like): Labels of the test set.
          prevs (np.ndarray): Artificial prevalences generated.

      Returns:
          List[tuple]: List of arguments for parallel processing.



.. py:class:: NPP(models: Union[List[Union[str, mlquantify.base.Quantifier]], str, mlquantify.base.Quantifier], batch_size: Union[List[int], int], learner: sklearn.base.BaseEstimator = None, n_iterations: int = 1, n_jobs: int = 1, random_state: int = 32, verbose: bool = False, return_type: str = 'predictions', measures: List[str] = None)

   Bases: :py:obj:`mlquantify.evaluation.protocol._Protocol.Protocol`


   Base class for implementing different quantification protocols.

   This abstract class provides a structure for creating protocols that involve
   fitting quantification models to training data and generating predictions on test data.
   It supports parallel processing, multiple iterations, and different output formats.

   Args:
       models (Union[List[Union[str, Quantifier]], str, Quantifier]): 
           List of quantification models, a single model name, or 'all' for all models.
       batch_size (Union[List[int], int]): 
           Size of the batches to be processed, or a list of sizes.
       learner (BaseEstimator, optional): 
           Machine learning model to be used with the quantifiers. Required for model methods.
       n_iterations (int, optional): 
           Number of iterations for the protocol. Default is 1.
       n_jobs (int, optional): 
           Number of jobs to run in parallel. Default is 1.
       random_state (int, optional): 
           Seed for random number generation. Default is 32.
       verbose (bool, optional): 
           Whether to print progress messages. Default is False.
       return_type (str, optional): 
           Type of return value ('predictions' or 'table'). Default is 'predictions'.
       measures (List[str], optional): 
           List of error measures to calculate. Must be in MEASURES or None. Default is None.


   .. py:method:: predict_protocol(X_test, y_test) -> tuple
      :abstractmethod:


      Abstract method that every protocol has to implement 



   .. py:method:: _new_sample(X, y, prev: List[float], batch_size: int) -> tuple
      :abstractmethod:


      Abstract method of sample extraction for each protocol

      Returns:
          tuple: tuple containing the X_sample and the y_sample



   .. py:method:: _delayed_predict(args) -> tuple
      :abstractmethod:


      abstract method for predicting in the extracted
      samples, is delayed for running in parallel for 
      eficciency purposes.



